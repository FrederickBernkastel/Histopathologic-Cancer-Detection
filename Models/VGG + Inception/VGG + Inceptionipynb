{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img, save_img\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Conv2D, GlobalMaxPooling2D,GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Concatenate, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.optimizers import SGD, Adam\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import cv2\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "\n",
    "train_data_dir = \"train_img\"\n",
    "test_dir=\"test_img\"\n",
    "img_size = (96,96)\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq():\n",
    "    sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "    seq = iaa.Sequential(\n",
    "        [\n",
    "            # apply the following augmenters to most images\n",
    "            iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
    "            iaa.Flipud(0.2), # vertically flip 20% of all images\n",
    "            sometimes(iaa.Affine(\n",
    "                scale={\"x\": (1., 1.1), \"y\": (1., 1.1)}, # scale images to 80-120% of their size, individually per axis\n",
    "#                 translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, # translate by -20 to +20 percent (per axis)\n",
    "                rotate=(-10, 10), # rotate by -45 to +45 degrees\n",
    "                shear=(-10, 10), # shear by -16 to +16 degrees\n",
    "                order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
    "#                 cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
    "                mode='reflect' # use any of scikit-image's warping modes\n",
    "            )),\n",
    "            # execute 0 to 3 of the following (less important) augmenters per image\n",
    "            # don't execute all of them, as that would often be way too strong\n",
    "            iaa.SomeOf((0, 3),\n",
    "                [\n",
    "#                     sometimes(iaa.Superpixels(p_replace=(0, .20), n_segments=(20, 200))), # convert images into their superpixel representation\n",
    "                    iaa.OneOf([\n",
    "                        iaa.GaussianBlur((0, 1.0)), # blur images with a sigma between 0 and 3.0\n",
    "                        iaa.AverageBlur(k=(3, 5)), # blur image using local means with kernel sizes between 2 and 7\n",
    "                        iaa.MedianBlur(k=(3, 5)), # blur image using local medians with kernel sizes between 2 and 7\n",
    "                    ]),\n",
    "#                     iaa.Sharpen(alpha=(0, .5), lightness=(0.9, 1.1)), # sharpen images\n",
    "#                     iaa.Emboss(alpha=(0, .5), strength=(0, 1.5)), # emboss images\n",
    "                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.01*255), per_channel=0.5), # add gaussian noise to images\n",
    "#                     iaa.OneOf([\n",
    "#                         iaa.Dropout((0.01, 0.05), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
    "#                         iaa.CoarseDropout((0.01, 0.03), size_percent=(0.01, 0.02), per_channel=0.2),\n",
    "#                     ]),\n",
    "#                     iaa.Invert(0.01, per_channel=True), # invert color channels\n",
    "                    iaa.Add((-10, 10), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
    "                    # change the brightness of the whole image (sometimes\n",
    "                    # per channel)\n",
    "                    iaa.Multiply((0.9, 1.1), per_channel=0.5),\n",
    "#                     sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), # move pixels locally around (with random strengths)\n",
    "#                     sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))), # sometimes move parts of the image around\n",
    "#                     sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n",
    "                ],\n",
    "                random_order=True\n",
    "            )\n",
    "        ],\n",
    "        random_order=True\n",
    "    )\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up image generators for data augmentation\n",
    "def my_gen(generator,is_augment=False):\n",
    "    while True:\n",
    "        x_batch,y_batch = next(generator)\n",
    "#         x_batch_view = x_batch.view('uint8')\n",
    "#         x_batch_view[:] = x_batch\n",
    "        x_batch = x_batch.astype('uint8',copy=False)\n",
    "        if is_augment:\n",
    "            x_batch = seq.augment_images(x_batch)\n",
    "        x_batch = preprocess_input(x_batch)\n",
    "        yield x_batch,y_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 176021 images belonging to 2 classes.\n",
      "Found 44004 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "seq=get_seq()\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    validation_split=.2,\n",
    "    dtype=np.uint8\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='training') # set as training data\n",
    "train_steps = len(train_generator)\n",
    "train_generator = my_gen(train_generator,is_augment=True)\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    train_data_dir, # same directory as training data\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation') # set as validation data\n",
    "validation_steps = len(validation_generator)\n",
    "validation_generator = my_gen(validation_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,callbacks=None,epochs=3,is_save=False):\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_steps, \n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_data=validation_generator, \n",
    "        validation_steps=validation_steps,\n",
    "        callbacks=callbacks,\n",
    "        use_multiprocessing=False\n",
    "    )\n",
    "    \n",
    "    if is_save:\n",
    "        model.save_weights('meta_model.h5')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For architecture, refer to below link\n",
    "# https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202\n",
    "def inception_v2(inputs,n_filters=6,kernel_size=(3,3),pool_size=(2,2),padding=\"same\"):\n",
    "    tower_0 = Conv2D(n_filters, (1,1), activation='relu', padding=padding)(inputs)\n",
    "    \n",
    "    tower_1 = MaxPooling2D(pool_size = pool_size,strides=1,padding=padding)(inputs)\n",
    "    tower_1 = Conv2D(n_filters, (1,1), activation='relu', padding=padding)(tower_1)\n",
    "    \n",
    "    tower_2 = Conv2D(n_filters, (1,1), activation='relu', padding=padding)(inputs)\n",
    "    tower_2_0 = Conv2D(n_filters, (3,1), activation='relu', padding=padding)(tower_2)\n",
    "    tower_2_1 = Conv2D(n_filters, (1,3), activation='relu', padding=padding)(tower_2)\n",
    "    \n",
    "    tower_3 = Conv2D(n_filters, (1,1), activation='relu', padding=padding)(inputs)\n",
    "    tower_3 = Conv2D(n_filters, (3,3), activation='relu', padding=padding)(tower_3)\n",
    "    tower_3_0 = Conv2D(n_filters, (3,1), activation='relu', padding=padding)(tower_3)\n",
    "    tower_3_1 = Conv2D(n_filters, (1,3), activation='relu', padding=padding)(tower_3)\n",
    "    \n",
    "    x = Concatenate(axis=3)([tower_0, tower_1, tower_2_0,tower_2_1,tower_3_0,tower_3_1])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the base pre-trained model\n",
    "# base_model = VGG16(weights='imagenet', include_top=False,input_shape=(36,36,3))\n",
    "base_model = VGG16(weights='imagenet', include_top=False,input_shape=(96,96,3))\n",
    "\n",
    "# Inception Block\n",
    "block0 = inception_v2(base_model.output)\n",
    "block0 = BatchNormalization()(block0)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "pred0 = GlobalAveragePooling2D()(block0)\n",
    "pred1 = GlobalMaxPooling2D()(block0)\n",
    "pred2 = Flatten()(block0)\n",
    "pred = Concatenate()([pred0,pred1,pred2])\n",
    "pred = Dropout(.5)(pred)\n",
    "# let's add a fully-connected layer\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "pred = Dense(1, activation='sigmoid')(pred)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=pred)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "for layer in model.layers[:1]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[1:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile AFTER freezing layer\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(0.0001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "2751/2751 [==============================] - 686s 249ms/step - loss: 0.3107 - acc: 0.8732 - val_loss: 0.2874 - val_acc: 0.8796\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.87960, saving model to best_model.h5\n",
      "Epoch 2/9\n",
      "2751/2751 [==============================] - 540s 196ms/step - loss: 0.2224 - acc: 0.9139 - val_loss: 0.2018 - val_acc: 0.9276\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.87960 to 0.92764, saving model to best_model.h5\n",
      "Epoch 3/9\n",
      "2751/2751 [==============================] - 540s 196ms/step - loss: 0.1971 - acc: 0.9256 - val_loss: 0.1893 - val_acc: 0.9276\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.92764 to 0.92764, saving model to best_model.h5\n",
      "Epoch 4/9\n",
      "2751/2751 [==============================] - 538s 196ms/step - loss: 0.1771 - acc: 0.9339 - val_loss: 0.1328 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.92764 to 0.95323, saving model to best_model.h5\n",
      "Epoch 5/9\n",
      "2751/2751 [==============================] - 538s 195ms/step - loss: 0.1650 - acc: 0.9388 - val_loss: 0.1387 - val_acc: 0.9512\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95323\n",
      "Epoch 6/9\n",
      "2751/2751 [==============================] - 538s 195ms/step - loss: 0.1543 - acc: 0.9425 - val_loss: 0.1163 - val_acc: 0.9616\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.95323 to 0.96159, saving model to best_model.h5\n",
      "Epoch 7/9\n",
      "2751/2751 [==============================] - 537s 195ms/step - loss: 0.1449 - acc: 0.9469 - val_loss: 0.1116 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.96159\n",
      "Epoch 8/9\n",
      "2751/2751 [==============================] - 536s 195ms/step - loss: 0.1377 - acc: 0.9494 - val_loss: 0.1273 - val_acc: 0.9565\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.96159\n",
      "Epoch 9/9\n",
      "2751/2751 [==============================] - 537s 195ms/step - loss: 0.1310 - acc: 0.9526 - val_loss: 0.1024 - val_acc: 0.9648\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.96159 to 0.96484, saving model to best_model.h5\n"
     ]
    }
   ],
   "source": [
    "train(model,callbacks = callbacks_list,epochs=9,is_save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we chose to train the top block, i.e. we will freeze\n",
    "# the first 4 blocks and unfreeze the rest:\n",
    "for layer in model.layers[:1]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[1:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "          optimizer=SGD(lr=.001, momentum=.01,nesterov=True,clipnorm=1.0),\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2751/2751 [==============================] - 522s 190ms/step - loss: 0.1554 - acc: 0.9451 - val_loss: 0.1195 - val_acc: 0.9594\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.94910 to 0.95944, saving model to best_model.h5\n",
      "Epoch 2/5\n",
      "2751/2751 [==============================] - 524s 190ms/step - loss: 0.1424 - acc: 0.9497 - val_loss: 0.1174 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.95944 to 0.96125, saving model to best_model.h5\n",
      "Epoch 3/5\n",
      "2751/2751 [==============================] - 525s 191ms/step - loss: 0.1412 - acc: 0.9502 - val_loss: 0.1132 - val_acc: 0.9626\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.96125 to 0.96264, saving model to best_model.h5\n",
      "Epoch 4/5\n",
      "2751/2751 [==============================] - 649s 236ms/step - loss: 0.1389 - acc: 0.9505 - val_loss: 0.1130 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.96264\n",
      "Epoch 5/5\n",
      "2751/2751 [==============================] - 522s 190ms/step - loss: 0.1370 - acc: 0.9514 - val_loss: 0.1124 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.96264 to 0.96284, saving model to best_model.h5\n"
     ]
    }
   ],
   "source": [
    "train(model,callbacks = callbacks_list, epochs=5,is_save=True) # Save model every epoch, re-reun def train cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs test time augmentation and outputs prediction on given model\n",
    "def predict(model,x_batch):\n",
    "    return (\n",
    "        model.predict(x_batch) + \n",
    "        model.predict(x_batch[:,::-1,:,:]) + \n",
    "        model.predict(x_batch[:,:,::-1,:]) + \n",
    "        model.predict(x_batch[:,::-1,::-1,:])\n",
    "    )/4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score =  0.9941507783021482\n",
      "Total Negatives in data:  130908  59.50%\n",
      "Total Positives in data:  89117  40.50%\n",
      "Confusion Matrix\n",
      " [[25688   469]\n",
      " [  882 17028]]\n",
      "0.680760534115562 0.5613825983313468\n",
      "1.5185460364633938\n"
     ]
    }
   ],
   "source": [
    "score=0\n",
    "batches=0\n",
    "conf_mat = np.empty((2,2),dtype=int)\n",
    "incorrect_preds = []\n",
    "i=0\n",
    "for x_batch,y_batch in validation_generator:\n",
    "    y_pred = predict(model,x_batch)\n",
    "    y_pred = y_pred.reshape(y_pred.size)\n",
    "    conf_mat += confusion_matrix(y_batch,y_pred>.5)\n",
    "    wrong_idxs = np.nonzero((y_pred>.5 )!= y_batch)\n",
    "    \n",
    "    for label,pred,img in zip(y_batch[wrong_idxs].tolist(),y_pred[wrong_idxs].tolist(),x_batch[wrong_idxs].tolist()):\n",
    "        incorrect_preds.append((int(label),pred))\n",
    "        img = array_to_img(img)\n",
    "        save_img(\"preview/%s/%d.tif\"%(int(label),i),x=img)\n",
    "        i+=1\n",
    "        \n",
    "    score += roc_auc_score(y_batch,y_pred)/validation_steps\n",
    "    batches += 1\n",
    "    \n",
    "    print(\"Val Batch %d/%d\\t\\t \" %(batches,validation_steps),end=\"\\r\")\n",
    "    if batches >= validation_steps:\n",
    "        break\n",
    "\n",
    "# AUC\n",
    "print(\"AUC score = \", score)\n",
    "\n",
    "# Confusion Matrix\n",
    "# tn, fp\n",
    "# fn, tp\n",
    "print(\"Total Negatives in data: \",130908, \" %.2f%%\"%(130908/(130908+89117)*100))\n",
    "print(\"Total Positives in data: \",89117, \" %.2f%%\"%(89117/(130908+89117)*100))\n",
    "print(\"Confusion Matrix\\n\", conf_mat)\n",
    "print(89117/130908.,471/839.)\n",
    "print(np.sum(conf_mat[:,0])/np.sum(conf_mat[:,1]))\n",
    "\n",
    "with open('analysis.csv', mode='w+',newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter=',')\n",
    "    writer.writerow(['label','pred'])\n",
    "    for label,pred in incorrect_preds:\n",
    "        writer.writerow((label,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('analysis.csv', mode='w+',newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter=',')\n",
    "    writer.writerow(['label','pred'])\n",
    "    for label,pred in incorrect_preds:\n",
    "        writer.writerow((label,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 96, 96, 64)   1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 96, 96, 64)   36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 48, 48, 64)   0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 48, 48, 128)  73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 48, 48, 128)  147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 24, 24, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 24, 24, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 24, 24, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 24, 24, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 12, 12, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 12, 12, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 12, 12, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 12, 12, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 6, 6, 512)    0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 6, 6, 512)    2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 6, 6, 512)    2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 6, 6, 512)    2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 3, 3, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 3, 3, 6)      3078        block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 3, 3, 512)    0           block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 3, 3, 6)      3078        block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 3, 3, 6)      330         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 3, 3, 6)      3078        block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 3, 3, 6)      3078        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 3, 3, 6)      114         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 3, 3, 6)      114         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 3, 3, 6)      114         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 3, 3, 6)      114         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 3, 36)     0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 3, 3, 36)     144         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 36)           0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalM (None, 36)           0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 324)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 396)          0           global_average_pooling2d_1[0][0] \n",
      "                                                                 global_max_pooling2d_1[0][0]     \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 396)          0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            397         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 14,728,327\n",
      "Trainable params: 14,728,255\n",
      "Non-trainable params: 72\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model.save_weights('modelv411.h5')\n",
    "# for i, layer in enumerate(base_model.layers):\n",
    "#     print(i, layer.name)\n",
    "\n",
    "model.load_weights('fullmodelv411.h5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict\n",
    "\n",
    "images = []\n",
    "img_names = []\n",
    "y_pred = []\n",
    "\n",
    "batch_count=0\n",
    "for img in os.listdir(test_dir):\n",
    "    img_names.append(img[:-4])\n",
    "    img = load_img(\"%s/%s\"%(test_dir,img), target_size=img_size)\n",
    "    img_arr = np.array(img)\n",
    "    images.append(img_arr)\n",
    "    img.close()\n",
    "    batch_count+=1\n",
    "    if batch_count>batch_size:\n",
    "        batch_count=0        \n",
    "        images = preprocess_input(np.array(images,dtype=float))\n",
    "        y_pred.extend((predict(model,images)).tolist())\n",
    "        images=[]\n",
    "else:\n",
    "    images = preprocess_input(np.array(images,dtype=float))\n",
    "#     images=datagen.standardize(np.array(images,dtype=float))\n",
    "    y_pred.extend(model.predict(images).tolist())\n",
    "    images=[]\n",
    "\n",
    "with open('submission.csv', mode='w+',newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter=',')\n",
    "    writer.writerow(['id','label'])\n",
    "    for idx,img_name in enumerate(img_names):\n",
    "        writer.writerow([img_name,y_pred[idx][0]])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
